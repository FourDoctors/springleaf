```{r setup, include=FALSE}

knitr::opts_chunk$set(cache=FALSE)
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(include=TRUE)
knitr::opts_chunk$set(results="asis")
knitr::opts_chunk$set(fig.width=12)
knitr::opts_chunk$set(fig.height=14)
prjpath <- "~/work/learn/competitions/kaggle/springleaf/"
datapath <- paste(prjpath, "data/", sep="")
analpath <- paste(prjpath, "analysis/", sep="")
rcodepath <- paste(analpath, "Rcode/", sep="")
setwd(analpath)

```

Some packages that we will use. Load other required passages at the
top, so that the user can know which of these they need to install.

```{r loadLibsAndSource, include=FALSE}

reqdpkgs <- c("lattice", "latticeExtra", "ggplot2", "reshape2",
              "plyr", "corrplot", "lubridate")
lapply(reqdpkgs, library, character.only=TRUE)

```

#Introduction

What is **Springleaf** about?

*Springleaf puts the humanity back into lending by offering their
customers personal and auto loans that help them take control of their
lives and their finances. Direct mail is onw important way
Springleaf's team can connect with customers who may be in need of a
loan.*

*Direct offers provide huge value to customers who need them, and are a
fundamental part of Springleaf's marketing strategy. In order to
improve their targeted efforts, Springleaf must be sure they are
focusing on the customers who are likely to respond and be good
candidates for their services.*

*Using a large set of anonymized features, Springleaf is asking you to
predict which customers will respond to a direct mail offer. You are
challenged to construct new meta-variables and employ
feature-selection methods to approach this dautingly wide dataset.*

The data provided does not have any labels! Any analysis will be
simpler if the variable names were somewhat descriptive. We will label
the variables by their types that we can infer.

First we load the data,

```{r dataload}

train <- read.csv(paste(datapath, 'train.csv', sep=""), stringsAsFactor=FALSE)
test <- read.csv(paste(datapath, 'test.csv', sep=""), stringsAsFactor=FALSE)

```
We should differentiate between the predictors and the outcome. This
is unnecessary in general, but useful in the case of this data.
```{r predout}

predictors <- names(train)[1:1933]
outcome <- names(train)[1934]

```
Before anything, we want to see if there are any columns without any values in them.

```{r allmissingcolumns}

N <- nrow(train)
all_missing <- sapply(predictors, function(p) sum(is.na(train[, p])) == N)
print(paste("Number of columns with missing data: ", sum(all_missing)))
predictors <- predictors[!all_missing]
train <- train[!all_missing]
test <- test[!all_missing]

```

#Datatypes

Notice that _predictors_ is a list of the names of the columns in the
data, and not the columns thenselves.

To determine the types of the variables, we will first look at all the
variables that were read by R as factors,
```{r factorvars}

trstr <- capture.output(str(train, list.len=2000))
facvars <-  grepl(x=trstr, pattern='chr')

```
The function _str_ returns strings describing the stucture of the data
passed to it. In its normal use, _str_ is used to print to the
screen. Above we have captured its output into a variable _trstr_
instead of printing it to the screen. While we can explore the
structure of the data by exploring the strings  in _trstr_ and
_facvars_,  we can use the function _class_ to directly obtain the type of each
column,

```{r datatypes}

predictor_types <- sapply(predictors, function(p) class(train[, p]))
print("Data types in the data frame train")
print(table(predictor_types))

```
We will separate the columns by their data-type,

```{r colByDataType}

predictors_chr <- predictors[predictor_types == 'character']
predictors_num <- predictors[predictor_types == 'integer' |
                                 predictor_types == 'numeric']

print(paste("number of numeric variables (including integer) is ",
            length(predictors_num)))

```

#Character variables

What might be the strings in the _character_ data be! These variables
could be logical, categorical, or dates. We will deal with these
individually.  First lets look at the number of distinct values in these
variables,

```{r numdistinctchrvars}

num_chr_var_vals <- data.frame(
    predictor=predictors_chr,
    num_vals = sapply(predictors_chr, function(p) length(unique(train[,p])))
)
print(num_chr_var_vals)

```

For any predictor with 10 or less distinct values, we can obtain their
values and look at them

```{r predictorscategorical}

maybe_cat <- sapply(
    predictors_chr,
    function(p) length(unique(train[,p])) < 11
)
categories_few <- lapply(
    predictors_chr[maybe_cat],
    function(p) unique(train[,p])
)
names(categories_few) <- predictors_chr[maybe_cat]
print(categories_few)

```

What are the variables that contain more than 10 unique values?
```{r manyvaluevars}

categories_many <- lapply(
    predictors_chr[!maybe_cat],
    function(p) unique(train[,p])
)
names(categories_many) <- predictors_chr[!maybe_cat]

```

Using the values in the _character_ variables we can hope to infer
what they measure. Some of these are dates, and we can write a
function to tell us if indeed they are. To this end we have
already peeked at the data to note that all date columns follow the
same format.

```{r datavars}

is.date <- function(values){
    data_months <- c('JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN',
                 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC')
    values <- values[values != '']
    all(
        sapply(values, function(v) {
                   any(
                       sapply(data_months, function(m) {
                                  grepl(x=v, pattern=m)
                              })
                       )

               })
        )
}

maybe_date <- sapply(
    predictors_chr,
    function(p) is.date(train[, p])
)
predictors_date <- predictors_chr[maybe_date]
print(paste("number of date predictors", sum(maybe_date)))

parsed_date <- function(ds) {
    # ignore the time in the timestamp
    dmy(lapply(strsplit(x=ds, split=":"),
               function(s) s[1]))
}

```

To be a logical variable, the value should be either _false_ or
_true_, or an empty string if NA.

```{r varlogical}

is_logical <- function(values){
    uv <- unique(values)
    length(uv) <= 3 &
    (any(grepl(x=uv, pattern='true')) |
     any(grepl(x=uv, pattern='false')) )
}

maybe_logical <- sapply(
    predictors_chr,
    function(p) is_logical(train[, p])
)

predictors_logical <- predictors_chr[maybe_logical]

print(paste("number of logical predictors", sum(maybe_logical)))

```
What are the remaining _character_ variables. There are a few with
many unique values. Lets look at the unique values of those that have
10 or fewer unique values,

```{r varnotlognotdate}

predictors_nld <- predictors_chr[ !maybe_logical & !maybe_date]
uvs_nld <- lapply(predictors_nld, function(p) unique(train[, p]))
names(uvs_nld) <- predictors_nld
num_val_nld <- data.frame(
    predictor = predictors_nld,
    num_vals = sapply(predictors_nld, function(p) length(unique(train[, p])))
)
uvs_nld[ with(num_val_nld, predictor[num_vals < 11])]

```
## Relabeling the character variables.
We can now begin to label make a dictionary that labels the variables.

```{r varlabels}

varlabels <- list()
n = 1
for(p in predictors_logical) {
    train[, p] <- as.logical(train[, p])
    test[, p] <- as.logical(test[,p])
    varlabels[p] <- paste('logical', n, sep='_')
    n = n + 1
}

n = 1
for(p in predictors_date){
    train[, p] <- parsed_date(train[, p])
    test[, p] <- parsed_date(test[,p])
    varlabels[p] <- paste('date', n, sep='_')
    n = n + 1
}

print('values of variable VAR_0001')
print(uvs_nld$VAR_0001)
varlabels$VAR_0001 <- 'hrq'

print('values of variable VAR_0005')
print(uvs_nld$VAR_0005)
varlabels$VAR_0005 <- 'cbns'

print('values of variable VAR_0044')
print(uvs_nld$VAR_0044)
varlabels$VAR_0044 <- 'isEmptyList'
train$VAR_0044 <- train$VAR_0044 == '[]'
test$VAR_0044 <- test$VAR_0044 == '[]'

print('values of variable VAR_0202')
print(uvs_nld$VAR_0202)
varlabels$VAR_0202 <- 'batchInquiry'
train$VAR_0202 <- train$VAR_0202 == 'BatchInquiry'
test$VAR_0202 <- test$VAR_0202 == 'BatchInquiry'

print('values of variable VAR_0216')
print(uvs_nld$VAR_0216)
varlabels$VAR_0216 <- 'ds'
train$VAR_0216 <- train$VAR_0216 == 'DS'
test$VAR_0216 <- test$VAR_0216 == 'DS'

print('values of variable VAR_0222')
print(uvs_nld$VAR_0222)
varlabels$VAR_0222 <- 'c6'
train$VAR_0222 <- train$VAR_0222 == 'C6'
test$VAR_0222 <- test$VAR_0222 == 'C6'

print('values of variable VAR_0283')
print(uvs_nld$VAR_0283)
varlabels$VAR_0283 <- 'shrug_first'
train$VAR_0283 <- as.factor(train$VAR_0283)
test$VAR_0283 <- as.factor(test$VAR_0283)

print('values of variable VAR_0305')
print(uvs_nld$VAR_0305)
varlabels$VAR_0305 <- 'shrug_second'
train$VAR_0305 <- as.factor(train$VAR_0305)
test$VAR_0305 <- as.factor(test$VAR_0305)

print('values of variable VAR_0325')
print(uvs_nld$VAR_0325)
varlabels$VAR_0325 <- 'shrug_third'
train$VAR_0325 <- as.factor(train$VAR_0325)
test$VAR_0325 <- as.factor(test$VAR_0325)

print('values of variable VAR_0352')
print(uvs_nld$VAR_0352)
varlabels$VAR_0352 <- 'oru_first'
train$VAR_0352 <- as.factor(train$VAR_0352)
test$VAR_0352 <- as.factor(test$VAR_0352)

print('values of variable VAR_0353')
print(uvs_nld$VAR_0353)
varlabels$VAR_0353 <- 'oru_second'
train$VAR_0353 <- as.factor(train$VAR_0353)
test$VAR_0353 <- as.factor(test$VAR_0353)

print('values of variable VAR_0354')
print(uvs_nld$VAR_0354)
varlabels$VAR_0354 <- 'oru_third'
train$VAR_0354 <- as.factor(train$VAR_0354)
test$VAR_0354 <- as.factor(test$VAR_0354)

print('values of variable VAR_0466')
print(uvs_nld$VAR_0466)
varlabels$VAR_0466 <- 'eye'
train$VAR_0466 <- as.factor(train$VAR_0466)
test$VAR_0466 <- as.factor(test$VAR_0466)

print('values of variable VAR_0467')
print(uvs_nld$VAR_0467)
varlabels$VAR_0467 <- 'status'
na0467 <- train$VAR_0467 == '-1' |  train$VAR_0467 == ''
train$VAR_0467[na0467] <- NA
train$VAR_0467 <- as.factor(train$VAR_0467)
test$VAR_0467 <- as.factor(test$VAR_0467)

print('values of variable VAR_1934')
print(uvs_nld$VAR_1934)
varlabels$VAR_1934 <- 'medium'
train$VAR_1934 <- as.factor(train$VAR_1934)
test$VAR_1934 <- as.factor(test$VAR_1934)

```
Whats left?

```{r manyvalvars}

print(num_val_nld[ num_val_nld$num_vals > 10,])

print("some of the values for the variable VAR_0200")
print(head(unique(train$VAR_0200), n=20))
varlabels$VAR_0200 <- 'city'

print("values for the variable VAR_0214")
print(unique(train$VAR_0214))
varlabels$VAR_0214 <- 'idused'

print("some of the values for the variable VAR_0237")
print(head(unique(train$VAR_0237)))
varlabels$VAR_0237 <- 'state_first'

print("some of the values for the variable VAR_0274")
print(head(unique(train$VAR_0274)))
varlabels$VAR_0274 <- 'state_second'

print("some of the values for the variable VAR_0342")
print(head(unique(train$VAR_0342), n=10))
varlabels$VAR_0342 <- 'abcdefu'

print("some of the values for the variable VAR_0404")
print(head(unique(train$VAR_0404), n=10))
varlabels$VAR_0404 <- 'job_first'

print("some of the values for the variable VAR_0493")
print(head(unique(train$VAR_0493), n=10))
varlabels$VAR_0493 <- 'job_second'

```

## Relabel the numeric variables

We will relabel the numeric variables as well

```{r renamenum}

numvarlabels <- as.list(paste("numeric", 1:(length(predictors_num)-1), sep="_"))
names(numvarlabels) <- predictors_num[-1]

vl <- c(varlabels, numvarlabels)
vl$ID <- 'ID'
vl$target <- 'target'
vlc <- as.character(vl)
names(vlc) <- names(vl)
names(train) <- vlc[names(train)]
names(test) <- vlc[names(test)]
```

We can write the resulting data-sets

```{r relabeleddata}
write.csv(train, file=paste(datapath, "train_labeled.csv", sep=""))
write.csv(test, file=paste(datapath, "test_labeled.csv", sep=""))
```


```{r setup, include=FALSE}

knitr::opts_chunk$set(cache=FALSE)
knitr::opts_chunk$set(echo=FALSE)
knitr::opts_chunk$set(include=TRUE)
knitr::opts_chunk$set(results="asis")
knitr::opts_chunk$set(fig.width=12)
knitr::opts_chunk$set(fig.height=14)
prjpath <- "~/work/learn/competitions/kaggle/springleaf/"
datapath <- paste(prjpath, "data/", sep="")
analpath <- paste(prjpath, "analysis/", sep="")
rcodepath <- paste(analpath, "Rcode/", sep="")
setwd(analpath)

```

```{r loadLibsAndSource, include=FALSE}

reqdpkgs <- c("lattice", "latticeExtra", "ggplot2", "reshape2",
              "plyr",  "lubridate", "Hmisc", "corrplot",
              "rpart", "rpart.plot", "rattle", "RWeka",
              "caret", "gbm", "randomForest")
lapply(reqdpkgs, library, character.only=TRUE)

```

Add sources here.
```{r sources}

source("../roc.R")

```

# Decision Trees to characterize the variables

We will use decision trees to characterize the predictor sets. For now
we assume that the datasets have been loaded in the environment, and
will fill in the details when we have time.

## Discrete encoded nunmeric variables

We can encode the discrete numeric variables (cluster X3 with entropy
smaller than 4 bits) with various levels of entropy-loss to reduce the
number of their distinct values. Which one is the best? We can answer
this question by running a decision tree to see if there is an effect
on the auc.

```{r encodedNums}

elosses <- c(1/8, 1/4, 1/2, 3/4)
fits.rpart.eloss.hc.num.X3 <- lapply(elosses,
                              function(max.loss) {
                                  data <- data.frame(
                                      lapply(train.model[, preds.num.X3.cats],
                                             function(xs) {
                                                 hxs <- huffman.encoded(xs,
                                                                        max.loss=max.loss)
                                                 print(paste("encoding for max-loss",
                                                             max.loss,
                                                             "entropy",
                                                             entropy(xs), "-->", entropy(hxs)
                                                             )
                                                       )
                                                 print(paste("encoding ",
                                                             "distinct",
                                                             length(unique(xs)), "-->",
                                                             length(unique(hxs))
                                                             )
                                                       )
                                                 print("----------------------------------")

                                                 hxs
                                             })
                                      )
                                  save(data, file=paste(
                                                 paste("../data/trainModelNumX3catsEloss",
                                                 max.loss, sep="-"), "Rdata", sep=".")
                                       )
                                  fit <- rpart(target ~ .,
                                               data = cbind(data,
                                                   data.frame(target=train$target)),
                                               control=rpart.control(cp=0.001,
                                                   depth=100, minsplit=10)
                                               )
                                  save(fit, file=paste( paste("../data/fitNumX3catsEloss",
                                                 max.loss, sep="-"), "Rdata", sep=".")
                                       )
                                  fit
                              })

auc.elosses <- sapply(fits.rpart.eloss.hc.num.X3,
                      function(fit) roc.auc(predict(fit), train$target)
                      )


print("effect of lossy encoding of discrete numerical variables")
print(data.frame(
    entropy.loss = elosses,
    auc.rpart = auc.elosses
    ))

```

We see that going from a loss of 0.125 bits to 0.750 reduced the auc
from by 0.04. The first thing to notice is that the auc itself is as
good as model.num.nz (that uses only the non-zero numerical variables
(preds.num.nz). This is probably because preds.num.X3.hc contain most
of the relevant information of preds.num.nz. We can see this by
looking at the decision trees for the fits.

```{r hcmodeltrees}

pdf(file="figures/treeEloss-0.125.pdf")
print(fancyRpartPlot(fits.rpart.eloss.hc.num.X3[[1]]))
dev.off()

pdf(file="figures/treeEloss-0.250.pdf")
print(fancyRpartPlot(fits.rpart.eloss.hc.num.X3[[2]]))
dev.off()

pdf(file="figures/treeEloss-0.500.pdf")
print(fancyRpartPlot(fits.rpart.eloss.hc.num.X3[[3]]))
dev.off()

pdf(file="figures/treeEloss-0.750.pdf")
print(fancyRpartPlot(fits.rpart.eloss.hc.num.X3[[4]]))
dev.off()
prp(fits.rpart.eloss.hc.num.X3[[1]], varlen=0)

```

We will use the 0.25 entropy loss.

## Data for models
We have noted in the prepare data code (in *prepareData.Rmd* or
*prepareData.R*) that the train and test data needs to be prepared
together. We have saved the results in the data/trainTest folder. We
will use this data for our models.

```{r loadsomedata}

load("../data/train_labeled.Rdata")
load("../data/test_labeled.Rdata")
N.train <- nrow(train)
N.test <- nrow(test)

```

```{r fitrpartnumnz}

if (!exists("train.and.test.num.nz")) {
    load("../data/trainTest/trainTestNumNZ.Rdata")
}

Y <- rep("NO", length=N.train)
Y[train$target == 1] <- "YES"
Y <- as.factor(Y)
train.num.nz <- train.and.test.num.nz[1:N.train,]
fit.rpart.nz <- rpart(target ~ .,
                      data = cbind(train.num.nz,
                          data.frame(target=Y)),
                      control=rpart.control(cp=0.001,
                          depth=100, minsplit=10)
                      )
print(roc.auc(predict(fit.rpart.num.nz), train$target))



```
The function _twoClassSummary_ from _caret_ does not seem to work,
returning NA for ROC. We will have to try our own,

```{r twoClassSummary}

ourTwoClassSummary <- function(data, lev=NULL, model=NULL) {
    rocObject <- roc(response=data$obs, predictor=data[, lev[1]])
    rocAUC <- rocObject$auc
    out <- c(rocAUC, sensitivity(data[, "pred"], data[, "obs"], lev[1]),
             specificity(data[, "pred"], data[, "obs"], lev[2]))
    names(out) <- c("ROC", "Sens", "Spec")
    out
}

```

Lets run a CV for rpart decision trees on non-num data,

```{r categoricalRpartCV}

if (!exists("train.and.test.non_num.treated")) {
    load("../data/trainTest/trainTestNonNumTreated.Rdata")
}
train.non_num <- train.and.test.non_num.treated[1:N.train, ]
test.non_num <- train.and.test.non_num.treated[(N.train + 1): (N.train + N.test),]

Y <- rep("NO", length=N.train)
Y[train$target == 1] <- "YES"
Y <- as.factor(Y)

fit.rpart.non_num <- rpart(target ~ .,
                           data = cbind(train.non_num,
                               data.frame(target=Y)),
                           control=rpart.control(cp=0.0008,
                               depth=100, minsplit=10)
                           )

print(roc.auc(predict(fit.rpart.non_num)[, 'YES'], train$target))


set.seed(100)
fit.rpart.non_num.cvtune.cp <- train(x = train.non_num,
                                     y = Y,
                                     method="rpart",
                                     tuneLength = 100,
                                     metric = "ROC",
                                     trControl = trainControl(
                                         summaryFunction = twoClassSummary,
                                         classProbs = TRUE,
                                         method = 'repeatedcv',
                                         repeats = 3)
                                     )

```

### A GBM model

```{r gbmtrainfunc}

fitgbm <- function(X,Y,
                   trControl = trainControl(
                       summaryFunction=twoClassSummary,
                       classProbs=TRUE,
                       method="repeatedcv",
                       number=10,
                       repeats=3),
                   grid = expand.grid (
                       interaction.depth=c(5,7,9),
                       n.trees=seq(400, 800, by=100),
                       shrinkage=c(0.01, 0.05, 0.1),
                       n.minobsinnode=10)
                   ) {
    gbmtune <- train(x = X, y = Y,
                     method="gbm",
                     metric="ROC",
                     tuneGrid=grid,
                     trControl=trControl)
    gbmtune

}

fitrpart <- function(X, Y,
                     trControl = trainControl(
                       summaryFunction=twoClassSummary,
                       classProbs=TRUE,
                       method="repeatedcv",
                       number=10,
                         repeats=3),
                     tunelength=10,
                     cp=TRUE) {

    method <- if (cp) "rpart" else "rpart2"
    rpartune <- train(x = X, y = Y,
                      method=method,
                      tuneLength = tunelength,
                      metric = "ROC",
                      trControl = trControl)
    rpartune
}


```


```{r gbmmodel1}

set.seed(100)
fitctrl <- trainControl(method="repeatedcv",
                        number=10,
                        repeats=2)
gbmGrid.0 <- expand.grid(interaction.depth=c(5,7,9),
                         n.trees=seq(400, 800, by=100),
                         shrinkage=c(0.01, 0.05, 0.1),
                         n.minobsinnode=10)
gbmtune.non_num.nz.g0 <- train(x=cbind(train.num.nz,
                                   train.non_num),
                               y=Y,
                               method='gbm',
                               metric='ROC',
                               tuneGrid=gbmGrid.0,
                               trControl=trainControl(
                                   summaryFunction=twoClassSummary,
                                   classProbs=TRUE,
                                   method="repeatedcv",
                                   number=10,
                                   repeats=3)
                               )

save(gbmGrid.0, file="../data/models/gbmTuneGrid0.Rdata")
save(gbmtune.non_num.nz.g0, file="../data/models/gbmtuneNonNumNZGrid0.Rdata")

rpart.non_num.nz.cvtune.cp <- train(x=cbind(train.num.nz,
                                        train.non_num),
                                    y=Y,
                                    method='rpart',
                                    trControl = trainControl(
                                        summaryFunction = twoClassSummary,
                                        classProbs = TRUE,
                                        method="repeatedcv",
                                        number=10,
                                        repeats=3)
                                    )

save(rpart.non_num.nz.cvtune.cp,
     file="../data/models/rpartNonNumNZcvtuneCP.Rdata")


```

## Catgegorical variables

There are not many categorical variables, so we can try a model with
all of them.

```{r fitcat}

fit.rpart.non_num.treated <- rpart(target ~ .,
                           data=cbind(train.model.non_num.treated,
                               data.frame(target=train$target)),
                           control=rpart.control(cp=0.001, depth=100, minsplit=10)
                                   )

print(roc.auc(predict(fit.rpart.non_num.treated), train$target))
save(fit.rpart.non_num.treated, file="../data/fits/rpart.non_num.treated")

```



Combine the categorical variables with the nz vars

```{r fitcatnz}

fit.rpart.non_num.nz <- rpart(target ~ .,
                              data=cbind(train.model.non_num.treated,
                                  train.model.num.nz,
                                  data.frame(target=train$target)
                                  ),
                              control=rpart.control(cp=0.001, depth=100, minsplit=10)
                              )
print(roc.auc(predict(fit.rpart.non_num.nz), train$target))

```

We can extract the important variables from our fit, and just use
those to see how well they predict

```{r fitimpvars}

vimp <- varImp(fit.rpart.non_num.nz)
vimp$variable <- row.names(vimp)
vimp <- vimp[order(vimp$Overall, decreasing=TRUE), ]
preds.non_num.nz.imp <- with(vimp, variable[Overall > 0])
print(paste("number of variables with position importance",
            length(preds.non_num.nz.imp))
      )

train.model.non_num.nz <- cbind(train.model.non_num.treated,
                                train.model.num.nz,)
control=rpart.control(cp=0.001, depth=100, minsplit=10)
fit.rpart.non_num.nz.imp <- rpart(target ~ .,
                                  data=cbind(
                                      train.model.non_num.nz[, preds.non_num.nz.imp],
                                      data.frame(target=train$target)
                                      ),
                                  control=control
                                  )

print(paste("when we use only the important variables we find an auc",
            roc.auc(predict(fit.rpart.non_num.nz.imp), train$target))
      )

```

Using only the important variables seems enough. We can use these and
add the ec variables.

```{r fitnonnumnzec}

primp.nz <- preds.non_num.nz.imp[grepl(pattern='numeric',
                                        x = preds.non_num.nz.imp)
                                  ]
primp.non <- preds.non_num.nz.imp[!grepl(pattern='numeric',
                                        x = preds.non_num.nz.imp)
                                  ]
fit.rpart.non.nz.ec <- rpart(target ~ .,
                             data=cbind(train.model.num.nz[, primp.nz],
                                 train.model.non_num.treated[, primp.non],
                                 train.model.num.ec),
                             control=control
                             )

```

We will use the variables' entropies and number NA to filter. Lets
save these in a dataframe

```{r varents}

var.entropies.X1 <- predictor.entropies(names(train.model.num.X1.ls),
                                        train.model.num.X1.ls, useNA=FALSE)
save(var.entropies.X1, file="../data/varEntropiesX1ls.Rdata")

var.entropies.X2 <- predictor.entropies(names(train.model.num.X2.ls),
                                        train.model.num.X2.ls, useNA=FALSE)
save(var.entropies.X2, file="../data/varEntropiesX2ls.Rdata")

var.entropies.X3.hc <- predictor.entropies(names(train.model.num.X3.cats.hc),
                                           train.model.num.X3.cats.hc, useNA=FALSE)
save(var.entropies.X3.hc, file="../data/varEntropiesX3hc.Rdata")

var.entropies.num.nz <- predictor.entropies(names(train.model.num.nz),
                                            train.model.num.nz, useNA=FALSE)
save(var.entropies.num.nz, file="../data/varEntropiesNumNZ.Rdata")

var.entropies.num.ec <- predictor.entropies(names(train.model.num.ec),
                                            train.model.num.ec, useNA=FALSE)
save(var.entropies.num.nz, file="../data/varEntropiesNumEC.Rdata")



var.entropies.non_num <- predictor.entropies(names(train.model.non_num.treated),
                                             train.model.non_num.treated, useNA=FALSE)
save(var.entropies.non_num, file="../data/varEntropiesNonNum.Rdata")

```

We will make models for NZ and EC data, and pick the predictors by
their importance for a full model,

```{r impvarsfunc}

importantVariables <- function(Xdata, Y,
                               control=rpart.control(depth=min(ncol(data), 100),
                                   minsplit=10,
                                   cp=0.001)
                               ) {
    fit <- rpart(target ~ .,
                 data=cbind(Xdata, data.frame(target=Y)),
                 control=control
                 )
    print(paste("fitted a model with auc",
                roc.auc(predict(fit), Y))
          )
    varimp <- varImp(fit)
    varimp$variable <- rownames(varimp)
    with(varimp, variable[Overall > 0])
}

```

```{r filterImpVars}

N <- nrow(train)
preds.fit.non_num <- importantVariables(
    train.model.non_num.treated[, with(var.entropies.non_num,
                                       variable[entropy > 0.5])],
    train$target
    )

preds.fit.num.X1 <- importantVariables(
    train.model.num.X1.ls[, with(var.entropies.X1,
                                 variable[entropy > 0.5 &
                                              nacount < N * 0.5]
                                 )
                         ],
    train$target
    )

preds.fit.num.X2 <- importantVariables(
    train.model.num.X2.ls[, with(var.entropies.X2,
                                 variable[entropy > 0.5 &
                                              nacount < N * 0.5]
                                 )
                          ],
    train$target
    )

preds.fit.num.X3.hc <- importantVariables(
    train.model.num.X3.cats.hc[, with(var.entropies.X3.hc,
                                 variable[entropy > 0.5 &
                                              nacount < N * 0.5]
                                 )
                          ],
    train$target
    )

preds.fit.num.ec <- importantVariables(
    train.model.num.ec[, with(var.entropies.num.ec,
                                 variable[entropy > 0.5 &
                                              nacount < N * 0.5]
                                 )
                          ],
    train$target
    )

preds.fit.num.nz <- importantVariables(
    train.model.num.nz[, with(var.entropies.num.nz,
                                 variable[entropy > 0.5 &
                                              nacount < N * 0.5]
                                 )
                          ],
    train$target
    )

```




```

Lets try a full model

```{r fullmodel}

preds.fit <- c(preds.fit.num.ec,
               preds.fit.num.nz,
               preds.fit.num.X1,
               preds.fit.num.X2,
               preds.fit.num.X3.hc,
               preds.fit.non_num
               )
train.fit <- cbind(train.model.non_num.treate,
                   train.model.num.treated)
train.fit <- train.fit[, preds.fit]
control <- rpart.control(depth=100, minsplit=10, cp=0.001)
fit.rpart.all <- rpart(target ~ .,
                       data=cbind(train.fit,
                           data.frame(target=train$target)
                                  ),
                       control=control
                       )
save(fit.rpart.all, file="../data/fitRpartAll")

```




```{r scratch}

data.test$date_7.year <- as.character(data.test$date_7.year)
data.test[data.test$date_7.year =="2007", 'date_7.year'] <- "2008"
data.test$date_7.year <- as.factor(data.test$date_7.year)
levels(data.test$date_7.year)


naed.unknownLevels <- function(data, p, unknown) {
    xs <- as.character(data[, p])
    xs[xs %in% unknown] <- NA
    as.factor(xs)
}

```
##Combine levels

We need to combine levels, train data does not have all the values that
the column might assume in test

```{r combinelevels}

combined.levels <- function(xs, ys) {
    cxs <- as.character(xs)
    cys <- as.character(ys)
    lxys <- levels(as.factor(c(cxs, cys)))
    list(factor(cxs, levels=lxys), factor(cys, levels=lxys))
}

```

## Submissions

### First mission

We will prepare data for our first submission,

```{r firstsubmission}

data.train <- cbind(train.model.num.X3.cats.hc[, preds.X3hc], train.model.non_num.treated)
data.test <- cbind(test.model.num.X3.cats.hc[, preds.X3hc], test.model.non_num.treated)

data.train$target <- train$target
fit1 <- rpart(target ~ ., data=data.train, control=control)

roc.auc(predict(fit1), train$target)

test.prediction <- data.frame(ID=test$ID, target=predict(fit1, newdata=data.test)



```


## Using pruned variables

We have created pruned variables, that we will now use for
predicting. We have also had problems with tuning GBMs. So we will
also train GBMs directly to debug.

```{r combineprunedvarsforprediction}

##assume the pp data to be loaded.
train.pp <- cbind(train.X1.nu.pp,
                  train.X1.nz.pp,
                  train.X1.ec.pp,
                  train.X2.pp,
                  train.X3.pp)

gbmodel <- gbm(target ~ .,
               data = cbind(train.pp,
                   data.frame(target=train$target) ),
               distribution = "bernoulli",
               interaction.depth = 9,
               n.trees = 100,
               shrinkage = 0.01,
               verbose = TRUE)

save(gbmodel, file="../data/models/gbmodel.pp.depth9.ntrees100.shrinkage01.Rdata")

```

The resuling model had a ROC of 0.7058721. We should compare this to
an rpart model.

```{r combinepprpart}

control = control=rpart.control(cp=0.001,
              depth=100, minsplit=10)
rpart.num.pp <- rpart(target ~ .,
                      data=cbind(train.pp,
                          data.frame(target=train$target) ),
                      control=control
                      )

save(rpart.num.pp, file="../data/models/rpart.num.pp.Rdata")

```



```{r withnonnum}

load("../data/trainTest/trainTestNonNumTreated.Rdata")
train.non_num <- train.and.test.non_num.treated[1:N.train,]



test.pp <- cbind(test.X1.nu.pp,
                 test.X1.nz.pp,
                 test.X1.ec.pp,
                 test.X2.pp,
                 test.X3.pp)

test.non_num <- train.and.test.non_num.treated[N.train + (1:N.test), ]
train.non_num <- train.non_num[ , sapply(train.non_num,
                                         function(xs) length(unique(xs[!is.na(xs)])) > 1)]

test.non_num <- test.non_num[ , names(train.non_num)]


logvars <- grepl(pattern="logical", x=names(train.non_num))
train.logical <- data.frame(lapply(train.non_num[, logvars],
                                   function(xs) as.numeric(xs)))
train.categorical <- train.non_num[, !logvars]

train.categorical$hasjob <- as.numeric(train.categorical$hasjob)

test.logical <- data.frame(lapply(test.non_num[, logvars],
                                   function(xs) as.numeric(xs)))
test.categorical <- test.non_num[, !logvars]
test.categorical$hasjob <- as.numeric(test.categorical$hasjob)

gbmodel <- gbm(target ~ .,
               data = cbind(train.pp,
                   train.logical, train.categorical,
                   data.frame(target=train$target) ),
               distribution = "bernoulli",
               interaction.depth = 9,
               n.trees = 1000,
               shrinkage = 0.01,
               verbose = TRUE)



test.gbmodel <- predict(gbmodel, n.trees=1000,
                        newdata = cbind(test.pp,
                            test.logical, test.categorical),
                        type="response"
                        )


prediction.gbmodel <- data.frame(ID = test$ID, target = test.gbmodel)
save(prediction.gbmodel, file="../data/predictions/prediction_gbm.num_pp.non_num.Rdata")
write.csv(prediction.gbmodel,
          file="../data/predictions/prediction_gbm.num_pp.non_num.csv",
          row.names=FALSE)



```


We can use xgboost instead of gbm, claimed to be 10 times faster. To
make things simpler for us, we will use a script on Kaggle to guide
the steps needed to prepare data for xgboost. In this script the
factor variables are converted to integers, and the NAs by -1. Since
we have already imputed the numerical columns, we will replace NAs for
only the factors (after these are converted to integers).


```{r xgboost}

train.combined <- cbind(train.pp,
                        train.categorical,
                        train.logical)

train.combined <- data.frame(lapply(train.combined,
                                    function(xs) {
                                        if (class(xs) == 'factor') as.integer(xs)
                                        else xs
                                    })
                             )
train.combined[is.na(train.combined)] <- -1

clf <- xgboost(data = data.matrix(train.combined),
               label = train$target,
               nrounds = 20,
               objective  = "binary:logistic",
               eval_metric = "auc")

test.combined <- cbind(test.pp,
                       test.categorical,
                       test.logical)
test.combined <- data.frame(lapply(test.combined,
                                   function(xs) {
                                       if(class(xs) == 'factor') as.integer(xs)
                                       else xs
                                   })
                            )
test.combined[is.na(test.combined)] <- -1

prediction.train <- predict(clf, data.matrix(train.combined))
cat(roc.auc(prediction.train, train$target), "\n")


```
To characterize the xgboost model better we need to develop a
cross-validation scheme for it. Since we cannot rely on caret for
this, we cook our own. Notice that now the data-set *training* will be
a part of the original train data, as well as *testing* a part of the
original train data.

```{r cvxgboost}
set.seed(100)
inTraining <- createDataPartition(train$target, p = 0.75, list=FALSE)
training <- train.combined[inTraining, ]
testing <- train.combined[-inTraining, ]

clf <- xgboost(data = data.matrix(training),
               label = train$target[inTraining],
               nrounds = 20,
               max.depth=10,
               eta=0.01,
               objective  = "binary:logistic",
               eval_metric = "auc")
prediction.testing <- predict(clf, data.matrix(testing))
cat("after partitioning train into a training and a testing data set the test AUC",
    roc.auc(prediction.testing, train$target[-inTraining]), "\n")


```

While we used the partitioned training to train and test the model
above, we should train the model on the complete train set before
getting predictions on the test.

```{r xgbfinalmodel}
trainAndPredict.xgb <- function(
    nrounds = 20,
    max.depth = 10,
    eta = 0.01 ) {

    clf <- xgboost(data = data.matrix(train.combined),
                   label = train$target,
                   nrounds = nrounds,
                   max.depth = max.depth,
                   eta = eta,
                   objective = "binary:logistic",
                   eval_metric = "auc")

    prediction.train <- predict(clf, data.matrix(train.combined))
    prediction.test <- predict(clf, data.matrix(test.combined))

    cat("training AUC", roc.auc(prediction.train, train$target))

    subm <- data.frame( ID = test$ID, target = prediction.test)
    paramstring <- paste(
        paste('nrounds', nrounds, sep="_"),
        paste('maxDepth', max.depth, sep="_"),
        paste('eta', eta, sep="_"),
        sep = ".")
    filename <- paste("prediction_xgb", paramstring, sep=".")
    write.csv(subm, file = paste("../data/predictions/", filename, sep="", row.names=FALSE))
}

```

Lets learn to use xgboost from an online tutorial. We will understand
the relevant parameters, and what they mean.

```{r fromxgboosttut}

bstDense <- xgboost(data = data.matrix(training),
                    label = train$target[inTraining],
                    max.depth=2,
                    eta=0.1,
                    nthread=3,
                    nround=100,
                    objective="binary:logistic",
                    eval_metric="auc")


prediction.testing <- predict(bstDense, data.matrix(testing))
cat("after partitioning train into a training and a testing data set the test AUC",
    roc.auc(prediction.testing, train$target[-inTraining]), "\n")

importance_matrix <- xgb.importance(model=bstDense)
print(importance_matrix)

```

We can also do CV with xgb,

```{r xgbcv}

bstDence.cv <- xgb.cv(param = list(max.depth=6, eta=0.01, silent=1,
                          nthread=3, objective='binary:logistic'),
                      data=xgb.DMatrix(data.matrix(training),
                          label = train$target[inTraining]),
                      nround = 20,
                      nfold = 5,
                      metrics = {'auc'})

```

At the github website of the R xgboost project we have found a caret
wrapper, that we implement for our data here. We are not sure if we
can get the tuning metric to be AUC.

```{r xgbcaretwrap}

require(data.table)

df <- data.table(cbind(training,
                       data.frame(target=train$target[inTraining])),
                 keep.rownames=FALSE)
fitControl <- trainControl(method="repeatedcv",
                           number = 10,
                           repeats = 3,
                           search = "random")
xgbmodel.tuning <- train(factor(target) ~ .,
                         data = df,
                         method = "xgbTree",
                         trControl = fitControl)

```

We will need to write our own hyper-parameter tuning for xgboost.

```{r tunexgb}

grid.xgb0 <- expand.grid(max.depth = c(6, 8, 10),
                         eta = c(0.01, 0.1, 1),
                         nrounds = c(10, 20, 40) )




